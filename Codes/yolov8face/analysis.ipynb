{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(1, '../../Src/')\n",
    "\n",
    "from utils import vision\n",
    "from utils import camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.yolov8face import model_yolo8face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize YOLOv8_face object detector\n",
    "YOLOv8_face_detector = model_yolo8face.YOLOv8_face(\"yolov8n-face.onnx\")\n",
    "#YOLOv8_face_detector = model_yolo8face.YOLOv8_face(\"yolov8-lite-s.onnx\")\n",
    "#YOLOv8_face_detector = model_yolo8face.YOLOv8_face(\"yolov8-lite-t.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.169] global net_impl.cpp:174 setUpNet DNN module was not built with CUDA backend; switching to CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "srcimg = cv2.imread('../../Src/images/1.jpg')\n",
    "\n",
    "# Detect Objects\n",
    "boxes, scores, classids, kpts = YOLOv8_face_detector.detect(srcimg)\n",
    "\n",
    "# Draw detections\n",
    "dstimg = YOLOv8_face_detector.draw_detections(srcimg, boxes, scores, kpts)\n",
    "#cv2.imwrite('result.jpg', dstimg)\n",
    "winName = 'Deep learning face detection use OpenCV'\n",
    "cv2.namedWindow(winName, 0)\n",
    "cv2.imshow(winName, dstimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[213.90427244, 184.70634498, 244.92698821, 329.72636751]]),\n",
       " array([0.8468767], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start webcam\n"
     ]
    }
   ],
   "source": [
    "COLOR_BOUNDINGBOX = (255, 0, 0)\n",
    "THICKNESS_BOUNDINGBOX = 2\n",
    "\n",
    "\n",
    "# For webcam input:\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = camera.ParallelCamera(2).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "my_fps = vision.FPS(100)\n",
    "\n",
    "my_fps_model = vision.FPS(100)\n",
    "\n",
    "\n",
    "while True:\n",
    "  my_fps.start()\n",
    "\n",
    "  # Read image\n",
    "  success, image = cap.read()  \n",
    "  # Flip the image horizontally for a selfie-view display.    \n",
    "  image = cv2.flip(image.copy(), 1)\n",
    "\n",
    "  image = cv2.resize(image,(300,300))\n",
    "  #time.sleep(0.5)\n",
    "\n",
    "  if not success:\n",
    "    print(\"Ignoring empty camera frame.\")\n",
    "    continue\n",
    "\n",
    "  my_fps_model.start()\n",
    "  \n",
    "  # Model Inference\n",
    "  image.flags.writeable = False\n",
    "  #predictions = model.predict(image)\n",
    "  boxes, scores = YOLOv8_face_detector.predict(image)\n",
    "  image.flags.writeable = True  \n",
    "  \n",
    "  # Draw bounding boxes\n",
    "  image = vision.draw_boundingboxes(image,boxes,COLOR_BOUNDINGBOX,THICKNESS_BOUNDINGBOX)\n",
    "  \n",
    "  # Calculate FPS\n",
    "  my_fps_model.update()\n",
    "  my_fps.update()\n",
    "  # Show image\n",
    "  image = vision.put_text(image,\"FPS      : \"+str(np.round(my_fps.fps(),3)),pos =(20,20))\n",
    "  image = vision.put_text(image,\"FPS model: \"+str(np.round(my_fps_model.fps(),3)),pos =(20,50))\n",
    "  cv2.imshow('Face Detection Project',image)\n",
    " \n",
    "  # Close window with ESC\n",
    "  if cv2.waitKey(5) & 0xFF == 27:\n",
    "    break\n",
    "\n",
    "# DestroyWindows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[121.63348732866325,\n",
       "  172.09099868054182,\n",
       "  179.62408804130064,\n",
       "  265.52373129378793]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3.10_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
