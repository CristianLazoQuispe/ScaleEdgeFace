{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUDA\n",
      "type id <class 'int'>\n",
      "start webcam id: 0...\n",
      "start webcam finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/cristian/12FF1F6D0CD48422/Tesis/env_3.10_com/lib/python3.10/site-packages/kornia/utils/image.py:40: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tensor: Tensor = torch.from_numpy(image)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "sys.path.insert(1, '../../Src/')\n",
    "\n",
    "from utils import vision\n",
    "from utils import camera\n",
    "\n",
    "COLOR_BOUNDINGBOX = (255, 0, 0)\n",
    "THICKNESS_BOUNDINGBOX = 2\n",
    "\n",
    "from models.kornia_face import model_kornia_face\n",
    "model = model_kornia_face.MODEL_kornia()\n",
    "\n",
    "\n",
    "\n",
    "cap = camera.ParallelCamera(0).start()\n",
    "my_fps = vision.FPS(100)\n",
    "my_fps_model = vision.FPS(100)\n",
    "\n",
    "try:\n",
    "\n",
    "  while True:\n",
    "    my_fps.start()\n",
    "\n",
    "    # Read image\n",
    "    success, image = cap.read()  \n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      break\n",
    "\n",
    "    image = cv2.flip(image.copy(), 1)\n",
    "    image = cv2.resize(image,(300,300))\n",
    "\n",
    "    my_fps_model.start()  \n",
    "    # Model Inference\n",
    "    image.flags.writeable = False\n",
    "    boxes, scores= model.predict(image)\n",
    "    image.flags.writeable = True  \n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    image = vision.draw_boundingboxes(image,boxes,COLOR_BOUNDINGBOX,THICKNESS_BOUNDINGBOX,if_wh=False)\n",
    "    \n",
    "    # Calculate FPS\n",
    "    my_fps_model.update()\n",
    "    my_fps.update()\n",
    "    # Show image\n",
    "    image = vision.put_text(image,\"FPS      : \"+str(np.round(my_fps.fps(),3)),pos =(20,20))\n",
    "    image = vision.put_text(image,\"FPS model: \"+str(np.round(my_fps_model.fps(),3)),pos =(20,50))\n",
    "    cv2.imshow('Face Detection Project',image)\n",
    "  \n",
    "    # Close window with ESC\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "except Exception as e:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    import sys\n",
    "    sys.exc_info()\n",
    "    print(traceback.format_exc())  # or: traceback.print_exc()\n",
    "    \n",
    "    \n",
    "# DestroyWindows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
